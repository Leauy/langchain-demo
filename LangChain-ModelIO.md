# ç¬¬2ç« ï¼šLangChainä½¿ç”¨ä¹‹Model I/O

## 1ã€Model I/Oä»‹ç»

Model I/Oæ¨¡å—æ˜¯ä¸è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œäº¤äº’çš„æ ¸å¿ƒç»„ä»¶ï¼Œåœ¨æ•´ä¸ªæ¡†æ¶ä¸­æœ‰å¾ˆé‡è¦çš„åœ°ä½ã€‚

æ‰€è°“çš„Model I/Oï¼ŒåŒ…æ‹¬è¾“å…¥æç¤ºï¼ˆFormatï¼‰ã€è°ƒç”¨æ¨¡å‹ï¼ˆPredictï¼‰ã€è¾“å‡ºè§£æï¼ˆParseï¼‰ã€‚åˆ†åˆ«å¯¹åº”Prompt Templateã€Modelå’ŒOutput parserã€‚

ç®€å•æ¥è¯´å°±æ˜¯è¾“å…¥ã€æ¨¡å‹å¤„ç†ã€è¾“å‡ºä¸‰ä¸ªæ­¥éª¤

![image-20260208224501403](E:\learn\AI-demo\langchain-demo\LangChain-ModelIO.assets\image-20260208224501403.png)

é’ˆå¯¹æ¯ä¸ªç¯èŠ‚ï¼ŒLangChain éƒ½æä¾›äº†æ¨¡æ¿å’Œå·¥å…·ï¼Œå¯ä»¥å¿«æ·çš„è°ƒç”¨å„ç§è¯­è¨€æ¨¡å‹çš„æ¥å£ã€‚

## 2ã€Model I/Oä¹‹è°ƒç”¨æ¨¡å‹1

LangChainä½œä¸ºä¸€ä¸ªå·¥å…·ï¼Œä¸æä¾›ä»»ä½•çš„LLMsï¼Œè€Œæ˜¯ä¾èµ–ç¬¬ä¸‰æ–¹é›†æˆå„ç§å¤§æ¨¡å‹ã€‚æ¯”å¦‚ï¼Œå°†OpenAIã€Anthropicã€Hugging Faceã€Llamaã€Qwenã€ç­‰å¹³å°çš„æ¨¡å‹æ— ç¼æ¥å…¥åˆ°ä½ çš„åº”ç”¨ã€‚

### 2.1 æ¨¡å‹çš„ä¸åŒåˆ†ç±»æ–¹å¼

ç®€å•æ¥è¯´å°±æ˜¯ç”¨è°å®¶çš„APIä»¥ä»€ä¹ˆæ–¹å¼è°ƒç”¨é‚£ç§ç±»å‹çš„å¤§æ¨¡å‹

#### è§’åº¦1ï¼šæŒ‰ç…§æ¨¡å‹åŠŸèƒ½çš„ä¸åŒ

- éå¯¹è¯æ¨¡å‹ï¼šLLMsã€text Model
- å¯¹è¯æ¨¡å‹ï¼šChat Modelsï¼ˆæ¨èï¼‰
- åµŒå…¥æ¨¡å‹ï¼ˆEmbedding Modelsï¼‰æš‚ä¸è€ƒè™‘

#### è§’åº¦2ï¼šæ¨¡å‹è°ƒç”¨æ—¶ï¼Œå‡ ä¸ªé‡è¦å‚æ•°çš„ä¹¦å†™ä½ç½®ä¸åŒ,api_keyï¼Œbase_url,model-name

- ç¡¬ç¼–ç æ–¹å¼ï¼šå°†å‚æ•°å†™åœ¨ä»£ç 
- ä½¿ç”¨ç¯å¢ƒå˜é‡çš„æ–¹å¼
- ä½¿ç”¨é…ç½®æ–‡ä»¶çš„æ–¹å¼ï¼ˆæ¨èï¼‰

#### è§’åº¦3ï¼šå…·ä½“APIçš„è°ƒç”¨

- ä½¿ç”¨LangChainæä¾›çš„APIï¼ˆæ¨èï¼‰
- ä½¿ç”¨OpenAIå®˜æ–¹çš„API
- ä½¿ç”¨å…¶ä»–å¹³å°æä¾›çš„API

OpenAIçš„GPTç³»åˆ—æ¨¡å‹å½±å“äº†å¤§æ¨¡å‹æŠ€æœ¯å‘å±•çš„å¼€å‘èŒƒå¼å’Œæ ‡å‡†ã€‚æ— è®ºæ˜¯Qwenè¿˜æ˜¯deepseekç­‰æ¨¡å‹ï¼Œä»–ä»¬ä½¿ç”¨çš„æ–¹æ³•å’Œå‡½æ•°è°ƒç”¨é€»è¾‘åŸºæœ¬ä¸Šéµå¾ªOpenAIå®šä¹‰çš„è§„èŒƒï¼Œæ²¡æœ‰å¤ªå¤§å·®å¼‚ã€‚è¿™å°±ä½¿å¾—å¤§éƒ¨åˆ†çš„å¼€æºé¡¹ç›®èƒ½å¤Ÿé€šè¿‡ä¸€ä¸ªè¾ƒä¸ºé€šç”¨çš„æ¥å£æ¥æ¥å…¥å’Œä½¿ç”¨ä¸åŒçš„æ¨¡å‹ã€‚

### 2.2 è§’åº¦1å‡ºå‘ï¼šæŒ‰ç…§åŠŸèƒ½ä¸åŒä¸¾ä¾‹

#### ç±»å‹1ï¼šLLMséå¯¹è¯æ¨¡å‹

LLMsï¼Œä¹Ÿå«TextModelï¼Œéå¯¹è¯æ¨¡å‹ï¼Œæ˜¯è®¸å¤šè¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºçš„æ”¯æŸ±ã€‚ä¸»è¦ç‰¹ç‚¹å¦‚ä¸‹ï¼š

- è¾“å…¥ï¼šæ¥å—æ–‡æœ¬å­—ç¬¦ä¸²æˆ–è€…PromptValueå¯¹è±¡
- è¾“å‡ºï¼šæ€»æ˜¯è¿”å›å­—ç¬¦ä¸²

![image-20260208225943214](E:\learn\AI-demo\langchain-demo\LangChain-ModelIO.assets\image-20260208225943214.png)

- é€‚ç”¨åœºæ™¯ï¼šä»…éœ€å•è¯æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦ç”Ÿæˆã€ç¿»è¯‘ã€ä»£ç ç”Ÿæˆã€å•æ¬¡é—®ç­”ï¼‰æˆ–å¯¹æ—¢ä¸æ”¯æŒæ¶ˆæ¯ç»“æ„çš„å°±æ¨¡å‹ï¼ˆå¦‚æœ¬åœ°éƒ¨ç½²æ¨¡å‹ï¼‰
- ä¸æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ã€‚æ¯æ¬¡è°ƒç”¨ç‹¬ç«‹å¤„ç†è¾“å…¥ï¼Œæ— æ³•è‡ªåŠ¨å…³è”å†å²å¯¹è¯ï¼ˆéœ€è¦æ‰‹åŠ¨æ‹¼æ¥å†å²æ–‡æœ¬ï¼‰
- å±€é™æ€§ï¼šæ— æ³•å¤„ç†è§’è‰²åˆ†å·¥æˆ–è€…å¤æ‚å¯¹è¯é€»è¾‘

æ¼”ç¤ºä»£ç å¦‚ä¸‹ï¼š

```python
import os
import dotenv

dotenv.load_dotenv()

from langchain_openai import ChatOpenAI
from langchain_core.messages import Message, SystemMessage, AIMessage

llm = ChatOpenAI(model='kimi-k2.5', api_key=os.getenv('DASHSCOPE_API_KEY'),base_url=os.getenv('DASHSCOPE_BASE_URL'))
print(llm.invoke('å®¶åº­è¦ä¸è¦ä¸€èµ·ç®¡é’±ï¼Ÿç»Ÿä¸€éƒ½ç»™åª³å¦‡ç®¡ç€ï¼Ÿ'))

```



#### ç±»å‹2ï¼šChat Models å¯¹è¯æ¨¡å‹

Chat Models ä¹Ÿå«èŠå¤©æ¨¡å‹ã€å¯¹è¯æ¨¡å‹ï¼Œåº•å±‚ä½¿ç”¨LLMs

å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨ï¼Œä»¥ChatModelä¸ºä¸»

ä¸»è¦ç‰¹ç‚¹ï¼š

- è¾“å…¥ï¼šæ¥å—æ¶ˆæ¯åˆ—è¡¨List[BaseMessage] æˆ–è€… PromptValueï¼Œæ¯æ¡æ¶ˆæ¯éœ€è¦æŒ‡å®šè§’è‰²å¦‚SystemMessageã€HumanMessageã€AIMessage
- è¾“å‡ºï¼šæ€»æ˜¯è¿”å›å¸¦ç€è§’è‰²çš„æ¶ˆæ¯å¯¹è±¡ï¼ˆBaseMessageå­ç±»ï¼‰é€šå¸¸æ˜¯AIMessage

![image-20260208230843357](E:\learn\AI-demo\langchain-demo\LangChain-ModelIO.assets\image-20260208230843357.png)

- åŸç”Ÿæ”¯æŒå¤šè½®å¯¹è¯ï¼šé€šè¿‡æ¶ˆæ¯åˆ—è¡¨ç»´æŠ¤ä¸Šä¸‹æ–‡ï¼Œä¾‹å¦‚SystemMessageã€HumanMessageã€AIMessageï¼Œã€‚ã€‚ã€‚ï¼‰æ¨¡å‹å¯ä»¥åŸºäºå®Œæ•´å¯¹è¯å†å²ç”Ÿæˆå›å¤ã€‚
- é€‚ç”¨åœºæ™¯ï¼šå¯¹è¯ç³»ç»Ÿï¼ˆå¦‚å®¢æœæœºå™¨äººã€é•¿æœŸäº¤äº’çš„AIåŠ©æ‰‹

æ¼”ç¤ºä»£ç å¦‚ä¸‹ï¼š

```python
import os
import dotenv
from langchain_openai import ChatOpenAI

dotenv.load_dotenv()

from langchain_core.messages import SystemMessage, AIMessage, HumanMessage

llm = ChatOpenAI(model='kimi-k2.5', api_key=os.getenv('DASHSCOPE_API_KEY'),base_url=os.getenv('DASHSCOPE_BASE_URL'))

messages = [
    SystemMessage(content='æˆ‘æ˜¯ç½‘ç»œè¿ç»´åŠ©æ‰‹ï¼Œæˆ‘å«marvelnet'),
    HumanMessage(content='æˆ‘å«åˆ˜æ´‹ï¼Œåä¸‰çš„é©»åœºè¿ç»´å·¥ç¨‹å¸ˆ')
]

from pprint import pprint

def pretty_ai_message(msg):
    print("ğŸ¤– AI Response:")
    print(msg.content)
    print("\n--- Metadata ---")
    pprint(msg.response_metadata)

response = llm.invoke(messages)

print(type(response))
print(response)
pretty_ai_message(response)
```

#### ç±»å‹3ï¼šåµŒå…¥æ¨¡å‹çš„è°ƒç”¨



```python
import traceback
from pprint import pprint

import dotenv, os

dotenv.load_dotenv()

from langchain_core.embeddings import Embeddings
from dashscope import MultiModalEmbedding
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document


class QwenEmbedding(Embeddings):
    def embed_documents(self, texts):
        vectors = []
        BATCH_SIZE = 16  # <=20

        for i in range(0, len(texts), BATCH_SIZE):
            batch = texts[i:i + BATCH_SIZE]

            resp = MultiModalEmbedding.call(
                model="multimodal-embedding-v1",
                input=batch,
                api_key=os.getenv("DASHSCOPE_API_KEY")
            )

            embs = resp["output"]["embeddings"]
            vectors.extend([e["embedding"] for e in embs])

        return vectors

    def embed_query(self, text):
        resp = MultiModalEmbedding.call(
            model="multimodal-embedding-v1",
            input=[text],
            api_key=os.getenv("DASHSCOPE_API_KEY")
        )
        return resp["output"]["embeddings"][0]["embedding"]


def process_text_file(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return [Document(page_content=f.read())]


docs = process_text_file("E:/learn/AI-demo/langchain-demo/README.md")

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
documents = splitter.split_documents(docs)
try:
    embedding_model = QwenEmbedding()
    pprint(embedding_model.embed_query('å¦‚ä½•è¿è¡Œæ¸¸æˆï¼Ÿ'))
except Exception as e:
    traceback.print_exc()

```

### 2.3 è§’åº¦2å‡ºå‘ï¼šå‚æ•°ä½ç½®ä¸åŒä¸¾ä¾‹

#### 2.3.1 æ¨¡å‹è°ƒç”¨çš„ä¸»è¦æ–¹æ³•ä»¥åŠå‚æ•°

ç›¸å…³æ–¹æ³•åŠå±æ€§

- OpenAI / ChatOpenAI ï¼šåˆ›å»ºä¸€ä¸ªæ¨¡å‹å¯¹è±¡ï¼ˆéå¯¹è¯ç±»/å¯¹è¯ç±»ï¼‰
- model.invode(xxx)ï¼šæ‰§è¡Œè°ƒç”¨ï¼Œå°†ç”¨æˆ·è¾“å…¥å‘é€ç»™æ¨¡å‹
- .content ï¼šæå–æ¨¡å‹è¿”å›çš„å®é™…æ–‡æœ¬å†…å®¹

æ¨¡å‹è°ƒç”¨å‡½æ•°ä½¿ç”¨æ—¶éœ€è¦åˆå§‹åŒ–æ¨¡å‹ï¼Œå¹¶è®¾ç½®å¿…è¦çš„å‚æ•°

1ã€å¿…é¡»è®¾ç½®çš„å‚æ•°Â·

- base_url: å¤§æ¨¡å‹APIæœåŠ¡çš„æ ¹åœ°å€
- api_key: ç”¨äºèº«ä»½éªŒè¯çš„å¯†é’¥ï¼Œç”±å¤§æ¨¡å‹æœåŠ¡å•†æä¾›
- model/model-name: æŒ‡å®šè¦è°ƒç”¨çš„å…·ä½“çš„å¤§æ¨¡å‹åç§°å¦‚deepseek-V3ï¼Œqwenç­‰

2ã€å…¶ä»–å‚æ•°

- temperatureï¼šæ¸©åº¦ï¼Œæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œå–å€¼èŒƒå›´0~1
  - å€¼è¶Šä½- è¾“å‡ºè¶Šç¡®å®šï¼Œä¿å®ˆï¼ˆé€‚åˆäº‹å®å›ç­”ï¼‰
  - å€¼è¶Šé«˜- è¾“å‡ºè¶Šå¤šæ ·ï¼Œæœ‰åˆ›æ„ï¼ˆé€‚åˆåˆ›æ„å†™ä½œï¼‰

é€šå¸¸æ ¹æ®éœ€è¦è®¾ç½®å¦‚ä¸‹ï¼š

- ç²¾ç¡®æ¨¡å¼ï¼ˆ0.5æˆ–è€…æ›´ä½ï¼‰ï¼šç”Ÿæˆçš„æ–‡æœ¬æ›´åŠ å®‰å…¨å¯é ï¼Œä½†æ˜¯ç¼ºä¹åˆ›æ„å’Œå¤šæ ·æ€§
- å¹³è¡¡æ¨¡å¼ï¼ˆ0.8ï¼‰ï¼šç”Ÿæˆçš„æ–‡æœ¬æ—¢æœ‰ä¸€å®šçš„å¤šæ ·æ€§ï¼Œåˆèƒ½ä¿æŒè¾ƒå¥½çš„è¿è´¯æ€§å’Œå‡†ç¡®æ€§ã€‚
- åˆ›æ„æ¨¡å¼ï¼ˆ1ï¼‰ï¼šç”Ÿæˆçš„æ–‡æœ¬æ›´å…·åˆ›æ„ï¼Œä½†æ˜¯ä¹Ÿæ›´å®¹æ˜“å‡ºç°è¯­æ³•é”™è¯¯æˆ–è€…ä¸åˆé€»è¾‘çš„å†…å®¹



- max_tokens: é™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦ï¼Œé˜²æ­¢è¾“å‡ºè¿‡é•¿

Tokenæ˜¯ä»€ä¹ˆï¼Ÿ

åŸºæœ¬å•ä½ï¼šå¤§æ¨¡å‹å¤„ç†æ–‡æœ¬çš„æœ€å°å•ä½æ—¶tokenï¼ˆç›¸å½“äºè‡ªç„¶è¯­è¨€ä¸­çš„è¯æˆ–è€…å­—ï¼‰ï¼Œè¾“å‡ºæ—¶é€ä¸ªtokenä¾æ¬¡ç”Ÿæˆ

æ”¶è´¹ä¾æ®ï¼šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šå¸¸æ˜¯ä»¥tokenæ•°é‡ä½œä¸ºå…¶è®¡é‡æ”¶è´¹çš„ä¾æ®

1tokenå¤§çº¦ 1-1.8ä¸ªä¸­æ–‡å­—ï¼Œå¤§çº¦3-4ä¸ªè‹±æ–‡å­—æ¯

tokenä¸å­—ç¬¦çš„è½¬åŒ–çš„å¯è§†åŒ–å·¥å…·

- https://platform.openai.com/tokenizer
- https://console.bce.baidu.com/support/#/tokenizer

max_tokensLå»ºè®®è®¾ç½®

- å®¢æˆ·çŸ­å›å¤ï¼š128-256
- å¸¸è§„å¯¹è¯ã€å¤šè½®å¯¹è¯ï¼š512-1024
- é•¿å†…å®¹ç”Ÿæˆï¼š1024-4096

#### 2.3.2 æ¨¡å‹è°ƒç”¨æ¨èå¹³å°ï¼šcloseai

è¿™é‡Œæ¨èä½¿ç”¨çš„å¹³å°

è€ƒè™‘åˆ°OpenAIç­‰æ¨¡å‹åœ¨å›½å†…æœåŠ¡è®¿é—®

#### 2.3.3 å‚æ•°ä½ç½®

- ç¡¬ç¼–ç 
- ç¯å¢ƒå˜é‡
- .envé…ç½®æ–‡ä»¶æ–¹å¼

![image-20260209000646263](E:\learn\AI-demo\langchain-demo\LangChain-ModelIO.assets\image-20260209000646263.png)

### 2.4 è§’åº¦3å‡ºå‘ï¼šå„å¹³å°APIçš„è°ƒç”¨ä¸¾ä¾‹

#### 2.4.1 OpenAIå®˜æ–¹API

è€ƒè™‘åˆ°OpenAIåœ¨å›½å†…è®¿é—®ä»¥åŠå……å€¼çš„ä¸ä¾¿ï¼Œæˆ‘ä»¬ä»ç„¶ä½¿ç”¨closeAIç½‘å€ https://www.closeai-asia.com æ³¨å†Œå’Œå……å€¼ï¼Œå…·ä½“è´¹ç”¨è‡ªç†ã€‚

##### è°ƒç”¨éå¯¹è¯æ¨¡å‹

```python
import dashscope
from dashscope import Generation
import os
import dotenv

dotenv.load_dotenv()
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")

resp = Generation.call(
    model="qwen-plus-2025-12-01",
    prompt="æŠŠä¸‹é¢çš„ä¸€æ®µè¯ç¿»è¯‘æˆä¸­æ–‡ï¼šActions speak louder than words."
)

print(resp.output.text)
```

##### è°ƒç”¨å¯¹è¯æ¨¡å‹

```python
import dashscope
import os
import dotenv

dotenv.load_dotenv()
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")


import os
from openai import OpenAI

client = OpenAI(
    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

completion = client.chat.completions.create(
    # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
    model="qwen-plus-2025-12-01",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "æŠŠä¸‹é¢çš„ä¸€æ®µè¯ç¿»è¯‘æˆä¸­æ–‡ï¼šActions speak louder than words."},
    ]
)
print(completion.choices[0].message)
```



### 2.5 å¦‚ä½•é€‰æ‹©åˆé€‚çš„å¤§æ¨¡å‹ï¼Ÿ

#### 2.5.1 æœ‰æ²¡æœ‰æœ€å¥½çš„å¤§æ¨¡å‹

å‡¡æ˜¯é—®é‚£ä¸ªå¤§æ¨¡å‹æœ€å¥½çš„ï¼Ÿéƒ½æ˜¯ä¸æ‡‚å¾—

ä¸å¦¨åé—®ï¼šæ— è®ºåšä»€ä¹ˆï¼Œæœ‰éƒ½è¡¨ç°æ›´å¥½çš„å‘˜å·¥çš„å—

æ²¡æœ‰æœ€å¥½çš„å¤§æ¨¡å‹ï¼Œåªæœ‰æœ€é€‚åˆçš„å¤§æ¨¡å‹

åŸºç¡€æ¨¡å‹é€‰å‹ï¼Œåˆè§„å’Œå®‰å…¨æ—¶é¦–è¦è€ƒé‡å› ç´ 

ä¸ºä»€ä¹ˆä¸è¦ä¾èµ–æ¦œå•ï¼Ÿ

- æ¦œå•ä»¥åŠè¢«åº”è¯•æ•™è‚²æ±¡æŸ“ï¼Œè¿˜ç®—å€¼å¾—ç›¸ä¿¡çš„æ¦œå•ï¼šLMSYS Chatbot Arena LeaderBoard
- æ¦œå•ä½“ç°çš„æ—¶æ•´ä½“èƒ½åŠ›ï¼Œæ”¾åˆ°ä¸€ä»¶å…·ä½“äº‹æƒ…ä¸Šï¼Œæ’åä½çš„å¯èƒ½åå€’æ›´å¥½
- æ¦œå•ä½“ç°ä¸å‡ºæˆæœ¬å·®å¼‚



æœ¬è¯¾ç¨‹ä¸»è¦ä»¥OpenAIä¸ºä¾‹å±•å¼€åç»­çš„è¯¾ç¨‹ã€‚å› ä¸ºï¼š

- OpenAIæœ€æµè¡Œï¼Œå³ä¾¿å›½å†…ä¹Ÿæ˜¯å¦‚æ­¤
- OpenAIæœ€å…ˆè¿›ï¼Œåˆ«çš„æ¨¡å‹æœ‰çš„èƒ½åŠ›ï¼ŒOpenAIä¸€å®šéƒ½iæœ‰ã€‚OpenAIæœ‰çš„ï¼Œå…¶ä»–æ¨¡å‹ä¸ä¸€å®šæœ‰
- å…¶ä»–æ¨¡å‹éƒ½åœ¨è¿½èµ¶å’Œæ¨¡ä»¿OpenAI

å­¦æ´»OpenAIï¼Œå…¶ä»–æ¨¡å‹è§¦ç±»æ—é€šåä¹‹ä¸ä¸€å®šã€‚

#### 2.5.2 å°ç»“ï¼šè·å–å¤§æ¨¡å‹çš„æ ‡å‡†æ–¹å¼

åç»­çš„å„ç§æ¨¡å‹æµ‹è¯•ï¼Œéƒ½åŸºäºä»¥ä¸‹çš„æ¨¡å‹å±•å¼€

**éå¯¹è¯æ¨¡å‹**

```python
import dashscope
from dashscope import Generation
import os
import dotenv

dotenv.load_dotenv()
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")

resp = Generation.call(
    model="qwen-plus-2025-12-01",
    prompt="æŠŠä¸‹é¢çš„ä¸€æ®µè¯ç¿»è¯‘æˆä¸­æ–‡ï¼šActions speak louder than words."
)

print(resp.output.text)
```

**å¯¹è¯æ¨¡å‹**

```python
import dashscope
import os
import dotenv

dotenv.load_dotenv()
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")


import os
from openai import OpenAI

client = OpenAI(
    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

completion = client.chat.completions.create(
    # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
    model="qwen-plus-2025-12-01",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "æŠŠä¸‹é¢çš„ä¸€æ®µè¯ç¿»è¯‘æˆä¸­æ–‡ï¼šActions speak louder than words."},
    ]
)
print(completion.choices[0].message)
```

## 3ã€Model I/Oä¹‹è°ƒç”¨æ¨¡å‹2

### 3.1 å…³äºå¯¹è¯æ¨¡å‹çš„Messageï¼ˆæ¶ˆæ¯ï¼‰

èŠå¤©æ¨¡å‹ï¼Œé™¤äº†å°†å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å‡ºã€‚

Langchainå†…ç½®æ¶ˆæ¯çš„ç±»å‹ï¼š

- System Messageï¼š è®¾å®šAIè¡Œä¸ºè§„åˆ™æˆ–è€…èƒŒæ™¯ä¿¡æ¯ï¼Œæ¯”å¦‚è®¾å®šAIçš„åˆå§‹çŠ¶æ€ã€è¡Œä¸ºæ¨¡å¼ã€æˆ–å¯¹è¯çš„æ€»ä½“ç›®æ ‡ã€‚æ¯”å¦‚ä½œä¸ºä¸€ä¸ªä»£ç ä¸“å®¶ï¼Œæˆ–è€…è¿”å›JSONæ ¼å¼ã€‚é€šå¸¸ä½œä¸ºæ¶ˆæ¯åºåˆ—ä¸­çš„ç¬¬ä¸€ä¸ªä¼ é€’
- HumanMessageï¼š è¡¨ç¤ºæ¥è‡ªç”¨æˆ·è¾“å…¥ï¼Œæ¯”å¦‚å®ç°ä¸€ä¸ªå¿«é€Ÿæ’åºçš„æ–¹æ³•
- AIMessageï¼šå­˜å‚¨AIå›å¤çš„å†…å®¹ï¼Œå¯ä»¥æ˜¯æ–‡æœ¬ï¼Œä¹Ÿå¯ä»¥æ—¶è°ƒç”¨å·¥å…·çš„è¯·æ±‚
- ChatMessageï¼šå¯ä»¥è‡ªå®šä¹‰è§’è‰²çš„é€šç”¨æ¶ˆæ¯ç±»å‹
- FuctionMessage/ToolMessageï¼šå‡½æ•°è°ƒç”¨/å·¥å…·æ¶ˆæ¯ï¼Œç”¨äºå‡½æ•°è°ƒç”¨ç»“æœçš„æ¶ˆæ¯ç±»å‹

æ³¨æ„
FuctionMessage/ToolMessageåˆ†åˆ«æ˜¯åœ¨å‡½æ•°è°ƒç”¨å’Œå·¥å…·è°ƒç”¨åœºæ™¯ä¸‹æ‰ä¼šä½¿ç”¨çš„ç‰¹æ®Šä¿¡æ¯ç±»å‹ï¼ŒHumanMessageã€AIMessageå’ŒSystemMessageæ‰æ˜¯æœ€å¸¸ç”¨çš„æ¶ˆæ¯ç±»å‹ã€‚

### 3.2 å…³äºä¸Šä¸‹æ–‡è®°å¿†

### 3.3 å…³äºæ¨¡å‹è°ƒç”¨çš„æ–¹æ³•

ä¸ºäº†å°½å¯èƒ½ç®€åŒ–è‡ªå®šä¹‰é“¾çš„åˆ›å»ºï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªRunnableçš„åè®®ã€‚è®¸å¤šå“Ÿçš„LangChainç»„ä»¶å®ç°äº†Runnableåè®®ï¼ŒåŒ…æ‹¬èŠå¤©æ¨¡å‹ã€‘æç¤ºè¯æ¨¡æ¿ã€è¾“å‡ºè§£æå™¨ã€æ£€ç´¢å™¨ã€ä»£ç†ï¼ˆæ™ºèƒ½ä½“ï¼‰ç­‰ã€‚

Runnableå®šä¹‰çš„å…¬å…±çš„è°ƒç”¨æ–¹æ³•å¦‚ä¸‹ï¼š

- invokeï¼š å¤„ç†å•æ¡è¾“å…¥ï¼Œç­‰å¾…LLMå®Œå…¨æ¨ç†å®Œæˆåå†è¿”å›è°ƒç”¨ç»“æœ
- streamï¼šæµå¼å“åº”ï¼Œé€å­—è¾“å‡ºLLMçš„å“åº”ç»“æœ
- batchï¼šå¤„ç†æ‰¹é‡è¾“å…¥

è¿™äº›ä¹Ÿæœ‰ç›¸åº”çš„å¼‚æ­¥æ–¹æ³•ï¼Œåº”è¯¥ä¸asyncio å’Œ await è¯­æ³•ä¸€èµ·ä»¥å®ç°å¹¶å‘ï¼š

- astreamï¼šå¼‚æ­¥æµå¼å“åº”
- ainvokeï¼šå¼‚æ­¥å¤„ç†å•æ¡è¾“å…¥
- abatchï¼šå¼‚æ­¥å¤„ç†æ‰¹é‡è¾“å…¥
- astream_log:å¼‚æ­¥æµå¼è¿”å›ä¸­é—´æ­¥éª¤ä»¥åŠæœ€ç»ˆå“åº”
- astream_events: æµ‹è¯•ç‰ˆå¼‚æ­¥æµå¼è¿”å›é“¾ä¸­å‘ç”Ÿçš„äº‹ä»¶ï¼ˆåœ¨langchain-core 0.1.4 ä¸­å¯ç”¨ï¼‰

#### 3.3.1 æµå¼è¾“å‡ºå’Œéæµå¼è¾“å‡º

åœ¨langchainä¸­ï¼Œè¯­è¨€æ¨¡å‹æ˜¯çš„è¾“å‡ºåˆ†ä¸ºäº†ä¸¤ç§ä¸»è¦çš„æ¨¡å¼ï¼šæµå¼è¾“å‡ºå’Œéæµå¼è¾“å‡º

ä¸‹é¢2ä¸ªåœºæ™¯

- éæµå¼è¾“å‡ºè¿™æ˜¯langchainä¸LLMäº¤äº’æ—¶é»˜è®¤çš„è¡Œä¸ºï¼Œæ˜¯æœ€ç®€å•ã€æœ€ç¨³å®šçš„è¯­è¨€æ¨¡å‹è°ƒç”¨æ–¹å¼ã€‚å½“ç”¨æˆ·å‘å‡ºè¯·æ±‚åï¼Œç³»ç»Ÿåœ¨åå°ç­‰å¾…æ¨¡å‹ç”Ÿæˆå®Œæ•´å“åº”ã€‚ç„¶åä¸€æ¬¡æ€§å°†å…¨éƒ¨ç»“æœè¿”å›
- æµå¼è¾“å‡ºï¼šä¸€ç§æ›´å…·äº¤äº’æ„Ÿçš„æ¨¡å‹è¾“å‡ºæ–¹å¼ï¼Œç”¨æˆ·ä¸å†éœ€è¦ç­‰å¾…å®Œæ•´ç­”æ¡ˆï¼Œè€Œæ˜¯èƒ½çœ‹åˆ°æ¨¡å‹é€ä¸ªtolenåœ°å®æ—¶è¿”å›å†…å®¹ã€‚

#### 3.3.2 æ‰¹é‡è°ƒç”¨

```python
import os

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

import dotenv

dotenv.load_dotenv()


client = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'), base_url=os.getenv('OPENAI_API_URL'),
                    model='qwen3-max-2026-01-23', streaming=True)

message1 = [SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éª¨ç§‘ä¸»ä»»'), HumanMessage(content='å°æ‹‡æŒ‡éª¨æŠ˜äº†ï¼Œå·²ç»7å‘¨äº†ï¼Œç›®å‰éª¨æŠ˜çº¿è¿˜æ˜¯å¾ˆæ˜æ˜¾ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ')]
message2 = [SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éª¨ç§‘ä¸»ä»»'), HumanMessage(content='æ’å¤éª¨ä¼¤æ„ˆåˆå‰‚è¿™ä¸ªèƒ½è¡Œå—ï¼Ÿ')]
message3 = [SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éª¨ç§‘ä¸»ä»»'), HumanMessage(content='æ’å¤éª¨ä¼¤æ„ˆåˆå‰‚è¿™ä¸ªèƒ½è¡Œå—ï¼Œæ¯æ¬¡å–å®Œå£ç‰¹åˆ«æ¸´ï¼Œè¿˜æœ‰ç‚¹å¤´æ™•ï¼Œæ­£å¸¸å—ï¼Ÿ')]

messages = [message1, message2, message3]
for message in client.batch(messages):
    print(message.content, end='', flush=True)


```

#### 3.3.3 åŒæ­¥è°ƒç”¨å’Œå¼‚æ­¥è°ƒç”¨

åŒæ­¥è°ƒç”¨ï¼šé˜»å¡å¼ï¼Œé¡ºåºæ‰§è¡Œ

å¼‚æ­¥è°ƒç”¨

å…è®¸ç¨‹åºåœ¨ç­‰å¾…æŸäº›æ“ä½œå®Œæˆæ—¶ç»§ç»­æ‰§è¡Œå…¶ä»–çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯é˜»å¡ç­‰å¾…ã€‚è¿™åœ¨å¤„ç†IOæ“ä½œï¼ˆå¦‚ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶è¯»å†™ç­‰ï¼‰æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ç¨‹åºçš„æ•ˆç‡å’Œå“åº”æ€§ã€‚

ä¸¾ä¾‹ï¼š

```python
import asyncio
import os
import time

from langchain_openai import ChatOpenAI
import dotenv

dotenv.load_dotenv()

async def model_call():

    client = ChatOpenAI(
        api_key=os.getenv('OPENAI_API_KEY'),
        base_url=os.getenv('OPENAI_API_URL'),
        model='qwen3-max-2026-01-23',
        streaming=False
    )
    for message in client.stream(
            'å°æ‹‡æŒ‡éª¨æŠ˜äº†ï¼Œå·²ç»7å‘¨äº†ï¼Œç›®å‰éª¨æŠ˜çº¿è¿˜æ˜¯å¾ˆæ˜æ˜¾ï¼Œè¯¥æ€ä¹ˆåŠï¼ŸåŒ»ç”Ÿå¼€äº†ä¸€äº›è¯ä¿ƒè¿›éª¨éª¼æ„ˆåˆçš„,ç›®å‰æœ‰åƒä¸€äº›é’™ç‰‡ï¼Œç‰›å¥¶ï¼Œé¸¡è›‹ï¼Œå¹³æ—¶åªæœ‰åœ¨æ•²é”®ç›˜çš„æ—¶å€™å¶å°”ä¼šå» æŠŠæ”¯æ¶æ‹†æ‰ï¼Œå¹³æ—¶éƒ½æ˜¯å¸¦ç€çš„ï¼Œå‡ ä¹æ²¡æ€ä¹ˆç”¨åŠ›'):
        print(message.content, end='', flush=True)

async def other_task():
    await asyncio.sleep(1)
    print('other_task finished')


async def main():
    start = time.time()
    await asyncio.gather(model_call(), other_task())
    end = time.time()
    print(end - start)
    return 'cost time: {}'.format(end - start)

if __name__ == '__main__':
    result = asyncio.run(main())
    print(result)
```

ä½¿ç”¨asyncio.gather()å¹¶è¡Œæ‰§è¡Œæ—¶ï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œä¸¤ä¸ªä»»åŠ¡å‡ ä¹åŒæ—¶å¼€å§‹ï¼Œä»–ä»¬çš„æ‰§è¡Œæ—¶é—´å°†é‡å ã€‚å¦‚æœä¸¤ä¸ªä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´ç›¸åŒï¼ˆ5sï¼‰é‚£ä¹ˆæ€»çš„æ‰§è¡Œæ—¶é—´åº”è¯¥æ¥è¿‘å•ä¸ªä»»åŠ¡çš„æ‰§è¡Œæ—¶é—´ï¼Œè€Œä¸æ˜¯ä¸¤è€…ä¹‹å’Œã€‚



å¼‚æ­¥è°ƒç”¨ä¹‹ainvoke

éªŒè¯ainvoke æ˜¯å¦æ—¶å¼‚æ­¥ï¼Ÿ

```python
import os
import inspect

from langchain_openai import ChatOpenAI
import dotenv

dotenv.load_dotenv()

client = ChatOpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    base_url=os.getenv('OPENAI_API_URL'),
    model='qwen3-max-2026-01-23',
    streaming=False
)


print('invoke æ˜¯åç¨‹å‡½æ•°' , inspect.iscoroutinefunction(client.invoke))
print('ainvoke æ˜¯åç¨‹å‡½æ•°' , inspect.iscoroutinefunction(client.ainvoke))

invoke æ˜¯åç¨‹å‡½æ•° False
ainvoke æ˜¯åç¨‹å‡½æ•° True
```





